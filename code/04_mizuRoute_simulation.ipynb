{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c0406a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# section 1 load all the necessary modules and packages\n",
    "import glob\n",
    "import time\n",
    "import netCDF4 as nc4\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "# not neccessary for the function but for visualziation\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import sys\n",
    "import os\n",
    "import platform\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a4d39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# replacing string function\n",
    "###########################\n",
    "def replace_string(file_in, file_out, replacement_dict):\n",
    "    \"\"\"\n",
    "    Replace strings in a text file using a dictionary of replacements and save the modified content to a new file.\n",
    "\n",
    "    Parameters:\n",
    "        file_in (str): Path to the input text file.\n",
    "        file_out (str): Path to the output text file.\n",
    "        replacement_dict (dict): Dictionary of old strings as keys and their corresponding replacements as values.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_in, \"r+\") as text_file:\n",
    "            texts = text_file.read()\n",
    "            for old_str, new_str in replacement_dict.items():\n",
    "                texts = texts.replace(old_str, new_str)\n",
    "\n",
    "        with open(file_out, \"w\") as text_file:\n",
    "            text_file.write(texts)\n",
    "\n",
    "        print(\"Strings replaced and saved successfully!\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        \n",
    "import xarray as xr\n",
    "\n",
    "def replace_and_save_netcdf(input_file, output_file, variable_values):\n",
    "    \"\"\"\n",
    "    Reads the input NetCDF file, replaces the specified variables with new values,\n",
    "    and saves the modified data as a new NetCDF file.\n",
    "\n",
    "    Parameters:\n",
    "        input_file (str): Path to the input NetCDF file.\n",
    "        output_file (str): Name of the output NetCDF file.\n",
    "        variable_values (dict): Dictionary of variable names and their corresponding new values.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the input NetCDF file using xarray\n",
    "        ds = xr.open_dataset(input_file)\n",
    "\n",
    "        # Replace variables with new values\n",
    "        for var_name, new_value in variable_values.items():\n",
    "            if var_name in ds:\n",
    "                ds[var_name].values[:] = new_value\n",
    "\n",
    "        # Save the modified data to the output NetCDF file\n",
    "        if os.path.isfile(output_file):\n",
    "            os.remove(output_file)\n",
    "        ds.to_netcdf(output_file)\n",
    "\n",
    "        # Close the dataset\n",
    "        ds.close()\n",
    "\n",
    "        print(f\"Data with modified variables saved to {output_file}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "def copy_folderA_to_folderB(path_org, path_target):\n",
    "    \"\"\"\n",
    "    Copy the contents of folder A into folder B and remove any files or folders in folder B\n",
    "    that are not present in folder A.\n",
    "\n",
    "    Parameters:\n",
    "        path_org (str): Path to the source folder A.\n",
    "        path_target (str): Path to the target folder B.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Check if the target folder B exists; if not, copy the entire folder A to B\n",
    "        if not os.path.isdir(path_target):\n",
    "            shutil.copytree(path_org, path_target)\n",
    "        else:\n",
    "            # Remove any files or folders in folder B that are not present in folder A\n",
    "            for root, dirs, files in os.walk(path_target):\n",
    "                for name in files + dirs:\n",
    "                    path = os.path.join(root, name)\n",
    "                    if not os.path.exists(os.path.join(path_org, os.path.relpath(path, path_target))):\n",
    "                        os.remove(path)\n",
    "\n",
    "        print(\"Folder A contents copied to folder B with cleanup.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        \n",
    "\n",
    "def gen_param(param_lim_low, param_lim_up, n):\n",
    "    \"\"\"\n",
    "    Generate random parameter values within specified lower and upper limits.\n",
    "\n",
    "    Parameters:\n",
    "        param_lim_low (numpy.ndarray): 1D array of lower limits for each parameter.\n",
    "        param_lim_up (numpy.ndarray): 1D array of upper limits for each parameter.\n",
    "        n (int): Number of sets of random parameter values to generate.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: A 2D array containing n sets of random parameter values, where each set is a row.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If param_lim_low and param_lim_up have different sizes or if any element in param_lim_low\n",
    "                    is greater than the corresponding element in param_lim_up.\n",
    "    \"\"\"\n",
    "    if len(param_lim_low) != len(param_lim_up):\n",
    "        raise ValueError(\"param_lim_low and param_lim_up must have the same size.\")\n",
    "\n",
    "    if np.any(param_lim_low > param_lim_up):\n",
    "        raise ValueError(\"Each element in param_lim_low must be less than or equal to the corresponding element in param_lim_up.\")\n",
    "\n",
    "    # Convert 1D arrays to 2D arrays of shape (n, num_parameters)\n",
    "    param_lim_low_2D = np.atleast_2d(param_lim_low.flatten()).repeat(repeats=n, axis=0)\n",
    "    param_lim_up_2D = np.atleast_2d(param_lim_up.flatten()).repeat(repeats=n, axis=0)\n",
    "\n",
    "    # Generate random numbers between 0 and 1 for each parameter\n",
    "    random = np.random.rand(n, len(param_lim_low.flatten()))\n",
    "\n",
    "    # Scale and shift the random numbers to be within the specified parameter limits\n",
    "    params = param_lim_low_2D + (param_lim_up_2D - param_lim_low_2D) * random\n",
    "\n",
    "    return params\n",
    "\n",
    "\n",
    "def slice_simulation(path, variables_to_keep, var_ID, target_IDs):\n",
    "    \n",
    "    for file_name in sorted(glob.glob(path)):\n",
    "\n",
    "        # open netcdf file\n",
    "        ds = xr.open_dataset(file_name)\n",
    "\n",
    "        # Drop all variables except the ones to keep with dimension of seg, time, or seg and time\n",
    "        variables_to_keep = ['IRFroutedRunoff', 'IRFvolume', 'time', 'reachID', 'time_bounds']\n",
    "        ds = ds.drop_vars([var for var in ds.variables if var not in variables_to_keep])\n",
    "        \n",
    "        # get the location of lake victoria and its outflow and slice\n",
    "        idx = np.where(np.isin(ds[var_ID].values, target_IDs))[0]\n",
    "        ds = ds.isel(seg = idx)\n",
    "\n",
    "        # save the file over the original file\n",
    "        os.remove(file_name)\n",
    "        ds.to_netcdf(file_name)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4739fad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  2.01        66.3          1.           1.        ]\n",
      " [  1.5787692   53.92912278   0.88704425   0.71209269]\n",
      " [  2.97917041 199.57686678   0.94395176   0.77507307]\n",
      " ...\n",
      " [  2.38248742  50.9746027    1.22292338   1.24973711]\n",
      " [  1.22439341 192.0164791    1.26579149   1.11612564]\n",
      " [  2.91982267 102.24993298   1.05579447   1.30582288]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'll' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yh/b1qy7zb96k980mcb2ps9n6d9t1c6zr/T/ipykernel_87368/3307770217.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mll\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# remove and create mizuRoute output folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'll' is not defined"
     ]
    }
   ],
   "source": [
    "# calibration of the parameters\n",
    "\n",
    "# generate the random parameters\n",
    "names=['HYP_Erate_emr','HYP_Qrate_emr','scale_factor_Ep_temp','scale_factor_P_temp']\n",
    "param_lim_low = np.array([1.00,  50.00, 0.60, 0.60])\n",
    "param_lim_up  = np.array([3.00, 200.00, 1.40, 1.40])\n",
    "param_num     = 10\n",
    "\n",
    "params = gen_param(param_lim_low, param_lim_up, param_num)\n",
    "\n",
    "# replace the first param with original parameter from agreed curve\n",
    "params [0,0] = 2.01\n",
    "params [0,1] = 66.3\n",
    "params [0,2] = 1.000\n",
    "params [0,3] = 1.000\n",
    "\n",
    "# remove and create mizuRoute output folder\n",
    "shutil.rmtree('../mizuRoute_output_all/', ignore_errors=True)\n",
    "os.makedirs('../mizuRoute_output_all/')\n",
    "np.savetxt(\"../mizuRoute_output_all/params.txt\", params, fmt=\"%.5f\")\n",
    "param_df = pd.DataFrame(params, columns=names)\n",
    "param_df.to_csv(\"../mizuRoute_output_all/params.csv\")\n",
    "\n",
    "# copy the set up to a new location\n",
    "shutil.rmtree('../mizuRoute_sim/', ignore_errors=True)\n",
    "copy_folderA_to_folderB('../mizuRoute/','../mizuRoute_sim/')\n",
    "os.chdir('../mizuRoute_sim/')\n",
    "os.system('chmod +x route_runoff.exe')\n",
    "\n",
    "# create the restart file at the start of year 2000\n",
    "# replace the values in the network topology for the HYPE formulation\n",
    "variable_values = {'HYP_Erate_emr':2.01,'HYP_Qrate_emr':66}\n",
    "replace_and_save_netcdf('./ancillary_data/Network_topology_lake_victoria.nc', './ancillary_data/Network_topology_lake_victoria.nc', variable_values)\n",
    "\n",
    "# prepare the control files based on the replacemenet\n",
    "replacement_dict = {'scale_factor_Ep_temp':str(\"{:.3f}\".format(1)), 'scale_factor_P_temp':str(\"{:.3f}\".format(1)), 'start_date_temp':'1979-01-01', 'end_date_temp':'1999-12-31'}\n",
    "replace_string('./settings/lake_victoria_temp.control', './settings/lake_victoria.control', replacement_dict)\n",
    "\n",
    "# execute the simulation\n",
    "os.system('rm ./output/*.h.*.nc') # make sure output folder is empty, keep restart file with *.r.*nc\n",
    "os.system('./route_runoff.exe ./settings/lake_victoria.control') # simulate mizuRoute\n",
    "\n",
    "# transfer the historic benchamrk before 2000 to mizuRoute output\n",
    "slice_simulation('./output/*.h.*.nc', ['IRFroutedRunoff', 'IRFvolume', 'time', 'reachID', 'time_bounds'],'reachID',[2062605, 7000016])\n",
    "command = 'module load cdo; cdo mergetime ./output/*.h.*.nc ./output/sim_hist.nc'\n",
    "os.system(command)\n",
    "command = 'mv ./output/sim_hist.nc '+'../mizuRoute_output_all/'+'sim_hist.nc'\n",
    "os.system(command)\n",
    "\n",
    "#\n",
    "m = 0\n",
    "for row in params:\n",
    "    \n",
    "    #\n",
    "    m = m + 1\n",
    "\n",
    "    # replace the values in the network topology for the HYPE formulation\n",
    "    variable_values = {'HYP_Erate_emr':row[0],'HYP_Qrate_emr':row[1]}\n",
    "    replace_and_save_netcdf('./ancillary_data/Network_topology_lake_victoria.nc','./ancillary_data/Network_topology_lake_victoria.nc',variable_values)\n",
    "\n",
    "    # prepare the control files based on the replacemenet\n",
    "    replacement_dict = {'scale_factor_Ep_temp':str(\"{:.3f}\".format(row[2])), 'scale_factor_P_temp':str(\"{:.3f}\".format(row[3])),'start_date_temp':'2000-01-01', 'end_date_temp':'2020-12-31', '!<fname_state_in>':'<fname_state_in> '}\n",
    "    replace_string('./settings/lake_victoria_temp.control','./settings/lake_victoria.control',replacement_dict)\n",
    "\n",
    "    # execute the simulation\n",
    "    os.system('rm ./output/*.h.*.nc') # make sure output folder is empty, keep restart file with *.r.*nc\n",
    "    os.system('./route_runoff.exe ./settings/lake_victoria.control') # simulate mizuRoute\n",
    "\n",
    "    # keep only two features from simulation, lake victoria and its outlet and save\n",
    "    slice_simulation('./output/*.h.*.nc', ['IRFroutedRunoff', 'IRFvolume', 'time', 'reachID', 'time_bounds'],'reachID',[2062605, 7000016])\n",
    "    command = 'module load cdo; cdo mergetime ./output/*.h.*.nc ./output/sim_'+str(m).zfill(5)+'.nc'\n",
    "    os.system(command)\n",
    "    command = 'mv ./output/sim_'+str(m).zfill(5)+'.nc '+'../mizuRoute_output_all/'+'sim_'+str(m).zfill(5)+'.nc'\n",
    "    os.system(command)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19560581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the simulation with lake for the lake using Doll formulation\n",
    "# prepare the control files based on the replacemenet\n",
    "replacement_dict = {'scale_factor_Ep_temp':str(\"{:.3f}\".format(1)),\\\n",
    "                    'scale_factor_P_temp':str(\"{:.3f}\".format(1)),\\\n",
    "                    'start_date_temp':'1979-01-01',\\\n",
    "                    'end_date_temp':'2020-12-31',\\\n",
    "                    '<varname_lakeModelType>    lake_type':'<varname_lakeModelType>    lake'} # use the lake flag as param definding doll\n",
    "replace_string('./settings/lake_victoria_temp.control','./settings/lake_victoria.control',replacement_dict)\n",
    "\n",
    "# execute the simulation\n",
    "os.system('rm ./output/*.h.*.nc') # make sure output folder is empty, keep restart file with *.r.*nc\n",
    "os.system('./route_runoff.exe ./settings/lake_victoria.control') # simulate mizuRoute\n",
    "\n",
    "# keep only two features from simulation, lake victoria and its outlet and save\n",
    "slice_simulation('./output/*.h.*.nc', ['IRFroutedRunoff', 'IRFvolume', 'time', 'reachID', 'time_bounds'],'reachID',[2062605, 7000016])\n",
    "command = 'module load cdo; cdo mergetime ./output/*.h.*.nc ./output/sim_Doll.nc'\n",
    "os.system(command)\n",
    "command = 'mv ./output/sim_Doll.nc'+'../mizuRoute_output_all/sim_Doll.nc'\n",
    "os.system(command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda18a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###########################\n",
    "# # get the evaporation for lake victoria \n",
    "# ###########################\n",
    "# file_names = sorted(glob.glob('../mizuRoute/input/mizuRoute_mswep_v1_*_subset.nc'))\n",
    "\n",
    "# datasets = [xr.open_dataset(file_name) for file_name in file_names]\n",
    "\n",
    "# merged_dataset = xr.concat(datasets, dim='time')\n",
    "\n",
    "# # number of years\n",
    "# time_variable = merged_dataset['time']\n",
    "# years = time_variable.dt.year\n",
    "# years = np.array(years)\n",
    "# n_years = np.unique(years)\n",
    "# print(n_years)\n",
    "\n",
    "# merged_dataset_slice = merged_dataset.sel(lat=-1.00, lon=33.00, method='nearest')\n",
    "\n",
    "# print(merged_dataset_slice)\n",
    "# merged_dataset_slice['evapw'].plot()\n",
    "\n",
    "# average_evap = sum(np.array(merged_dataset_slice['evapw'][:]))/len(n_years)\n",
    "\n",
    "# print(average_evap)\n",
    "\n",
    "# # get the ratio for scale\n",
    "# other_evap = np.array([average_evap, 1550, 1350, 1130, 1520, 1450, 1500, 1370, 1590, 1470, 1475, 1590, 1595, 1400])\n",
    "\n",
    "# # creat the scale factors\n",
    "# scales = other_evap/average_evap\n",
    "\n",
    "# # the control to create the restart file\n",
    "# m = 0\n",
    "# job_string = ''\n",
    "# for scale in scales:\n",
    "    \n",
    "#     case_name = str(m)\n",
    "#     scale_value = str(\"{:.3f}\".format(scale))\n",
    "    \n",
    "#     replace_string ('../mizuRoute/settings/lake_victoria_temp.control',\\\n",
    "#                     '../mizuRoute/settings/lake_victoria_'+case_name+'.control',\\\n",
    "#                     ['case_temp','scale_factor_temp'],\\\n",
    "#                     ['case_'+case_name+'_'+scale_value,scale_value])\n",
    "    \n",
    "#     replace_string ('../mizuRoute/settings/lake_victoria_'+case_name+'.control',\\\n",
    "#                     '../mizuRoute/settings/lake_victoria_'+case_name+'_restart.control',\\\n",
    "#                     ['!<fname_state_in>'],\\\n",
    "#                     ['<fname_state_in> '])\n",
    "    \n",
    "#     m +=1\n",
    "    \n",
    "#     # add to general string\n",
    "#     job_string = job_string + '# case'+ case_name +'\\n'\n",
    "#     job_string = job_string + 'srun ./route_runoff.exe ./settings/lake_victoria_'+case_name+'.control \\n' +\\\n",
    "#                               'mv ./output/case_'+case_name+'_'+scale_value+'.r.2014-01-01-00000.nc ./output/case_'+case_name+'_'+scale_value+'.r.1979-01-01-00000.nc \\n'+\\\n",
    "#                               'srun ./route_runoff.exe ./settings/lake_victoria_'+case_name+'_restart.control \\n'\n",
    "#     job_string = job_string + '\\n'\n",
    "    \n",
    "    \n",
    "\n",
    "# shutil.copy('../mizuRoute/lake_victoria_temp.submit', '../mizuRoute/lake_victoria.submit')\n",
    "# with open('../mizuRoute/lake_victoria.submit', \"a\") as file:\n",
    "#     file.write(job_string)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fhimp_venv",
   "language": "python",
   "name": "fhimp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
